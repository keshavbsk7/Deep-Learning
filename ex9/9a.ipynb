{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RBM:\n",
    "    def __init__(self, num_visible, num_hidden, learning_rate=0.1, epochs=100, batch_size=10):\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.weights = np.random.randn(num_visible, num_hidden) * 0.1\n",
    "        self.visible_bias = np.zeros(num_visible)\n",
    "        self.hidden_bias = np.zeros(num_hidden)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def gibbs_sampling(self, visible_prob):\n",
    "        hidden_prob = self.sigmoid(np.dot(visible_prob, self.weights) + self.hidden_bias)\n",
    "        hidden_state = np.random.binomial(1, hidden_prob)\n",
    "\n",
    "        visible_recon_prob = self.sigmoid(np.dot(hidden_state, self.weights.T) + self.visible_bias)\n",
    "        visible_recon = np.random.binomial(1, visible_recon_prob)\n",
    "\n",
    "        return hidden_state, visible_recon\n",
    "\n",
    "    def contrastive_divergence(self, input_data):\n",
    "        num_samples = input_data.shape[0]\n",
    "\n",
    "        positive_hidden_prob = self.sigmoid(np.dot(input_data, self.weights) + self.hidden_bias)\n",
    "        positive_associations = np.dot(input_data.T, positive_hidden_prob)\n",
    "\n",
    "        hidden_state = np.random.binomial(1, positive_hidden_prob)\n",
    "        negative_visible_prob = self.sigmoid(np.dot(hidden_state, self.weights.T) + self.visible_bias)\n",
    "        negative_hidden_prob = self.sigmoid(np.dot(negative_visible_prob, self.weights) + self.hidden_bias)\n",
    "        negative_associations = np.dot(negative_visible_prob.T, negative_hidden_prob)\n",
    "\n",
    "        self.weights += self.learning_rate * ((positive_associations - negative_associations) / num_samples)\n",
    "        self.visible_bias += self.learning_rate * np.mean(input_data - negative_visible_prob, axis=0)\n",
    "        self.hidden_bias += self.learning_rate * np.mean(positive_hidden_prob - negative_hidden_prob, axis=0)\n",
    "\n",
    "    def train(self, data):\n",
    "        num_batches = len(data) // self.batch_size\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for batch in range(num_batches):\n",
    "                batch_data = data[batch * self.batch_size : (batch + 1) * self.batch_size]\n",
    "                self.contrastive_divergence(batch_data)\n",
    "\n",
    "            reconstruction_error = np.mean(np.abs(data - self.reconstruct(data)))\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs}, Reconstruction Error: {reconstruction_error}\")\n",
    "\n",
    "    def reconstruct(self, data):\n",
    "        hidden_prob = self.sigmoid(np.dot(data, self.weights) + self.hidden_bias)\n",
    "        visible_recon_prob = self.sigmoid(np.dot(hidden_prob, self.weights.T) + self.visible_bias)\n",
    "        return visible_recon_prob\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_visible_units = 10\n",
    "    num_hidden_units = 5\n",
    "    rbm = RBM(num_visible=num_visible_units, num_hidden=num_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Reconstruction Error: 0.4981227668361333\n",
      "Epoch 2/100, Reconstruction Error: 0.4968361242861507\n",
      "Epoch 3/100, Reconstruction Error: 0.4959885428481622\n",
      "Epoch 4/100, Reconstruction Error: 0.4954310249264029\n",
      "Epoch 5/100, Reconstruction Error: 0.4949726663994579\n",
      "Epoch 6/100, Reconstruction Error: 0.4946339936104566\n",
      "Epoch 7/100, Reconstruction Error: 0.49430932404491773\n",
      "Epoch 8/100, Reconstruction Error: 0.4938966896058109\n",
      "Epoch 9/100, Reconstruction Error: 0.4934878739311935\n",
      "Epoch 10/100, Reconstruction Error: 0.4931551906155756\n",
      "Epoch 11/100, Reconstruction Error: 0.49271643401318505\n",
      "Epoch 12/100, Reconstruction Error: 0.4920809915479637\n",
      "Epoch 13/100, Reconstruction Error: 0.4915218594956124\n",
      "Epoch 14/100, Reconstruction Error: 0.4908061382005786\n",
      "Epoch 15/100, Reconstruction Error: 0.49020794667327094\n",
      "Epoch 16/100, Reconstruction Error: 0.489287593957046\n",
      "Epoch 17/100, Reconstruction Error: 0.48828871776287247\n",
      "Epoch 18/100, Reconstruction Error: 0.4872968983435972\n",
      "Epoch 19/100, Reconstruction Error: 0.48623585966176064\n",
      "Epoch 20/100, Reconstruction Error: 0.48481564947748\n",
      "Epoch 21/100, Reconstruction Error: 0.4832626806595489\n",
      "Epoch 22/100, Reconstruction Error: 0.4820197641621761\n",
      "Epoch 23/100, Reconstruction Error: 0.4803099340961782\n",
      "Epoch 24/100, Reconstruction Error: 0.47869709533849664\n",
      "Epoch 25/100, Reconstruction Error: 0.47674263392142585\n",
      "Epoch 26/100, Reconstruction Error: 0.4748297723527813\n",
      "Epoch 27/100, Reconstruction Error: 0.4725696041797383\n",
      "Epoch 28/100, Reconstruction Error: 0.4700257624567583\n",
      "Epoch 29/100, Reconstruction Error: 0.4678070934406405\n",
      "Epoch 30/100, Reconstruction Error: 0.4652159881252852\n",
      "Epoch 31/100, Reconstruction Error: 0.4622815344710441\n",
      "Epoch 32/100, Reconstruction Error: 0.4593361689258537\n",
      "Epoch 33/100, Reconstruction Error: 0.4566895386851759\n",
      "Epoch 34/100, Reconstruction Error: 0.45332688006377514\n",
      "Epoch 35/100, Reconstruction Error: 0.4497921066768146\n",
      "Epoch 36/100, Reconstruction Error: 0.4466789167431091\n",
      "Epoch 37/100, Reconstruction Error: 0.4434975101293057\n",
      "Epoch 38/100, Reconstruction Error: 0.44057922491045276\n",
      "Epoch 39/100, Reconstruction Error: 0.4371734217987413\n",
      "Epoch 40/100, Reconstruction Error: 0.4339154280717454\n",
      "Epoch 41/100, Reconstruction Error: 0.4306269846990883\n",
      "Epoch 42/100, Reconstruction Error: 0.42719113096408406\n",
      "Epoch 43/100, Reconstruction Error: 0.42427928906482887\n",
      "Epoch 44/100, Reconstruction Error: 0.42084579330801297\n",
      "Epoch 45/100, Reconstruction Error: 0.4173735656375825\n",
      "Epoch 46/100, Reconstruction Error: 0.4143883966332264\n",
      "Epoch 47/100, Reconstruction Error: 0.4117925770672863\n",
      "Epoch 48/100, Reconstruction Error: 0.40823753116130684\n",
      "Epoch 49/100, Reconstruction Error: 0.40525849233209915\n",
      "Epoch 50/100, Reconstruction Error: 0.40237446677119565\n",
      "Epoch 51/100, Reconstruction Error: 0.399891841251835\n",
      "Epoch 52/100, Reconstruction Error: 0.3969581466141673\n",
      "Epoch 53/100, Reconstruction Error: 0.3940430212429521\n",
      "Epoch 54/100, Reconstruction Error: 0.3917134561584047\n",
      "Epoch 55/100, Reconstruction Error: 0.3893315478502948\n",
      "Epoch 56/100, Reconstruction Error: 0.3864307719922672\n",
      "Epoch 57/100, Reconstruction Error: 0.3840423394439375\n",
      "Epoch 58/100, Reconstruction Error: 0.38152816649715\n",
      "Epoch 59/100, Reconstruction Error: 0.37886015580410615\n",
      "Epoch 60/100, Reconstruction Error: 0.3768797835952182\n",
      "Epoch 61/100, Reconstruction Error: 0.37487592257815133\n",
      "Epoch 62/100, Reconstruction Error: 0.3727065794341913\n",
      "Epoch 63/100, Reconstruction Error: 0.3708149425557948\n",
      "Epoch 64/100, Reconstruction Error: 0.3684742892060725\n",
      "Epoch 65/100, Reconstruction Error: 0.3665713108592868\n",
      "Epoch 66/100, Reconstruction Error: 0.36470907585233114\n",
      "Epoch 67/100, Reconstruction Error: 0.36300473174250125\n",
      "Epoch 68/100, Reconstruction Error: 0.36135519641196745\n",
      "Epoch 69/100, Reconstruction Error: 0.3597070039597962\n",
      "Epoch 70/100, Reconstruction Error: 0.3581970029001715\n",
      "Epoch 71/100, Reconstruction Error: 0.3566710441024415\n",
      "Epoch 72/100, Reconstruction Error: 0.3547548498730985\n",
      "Epoch 73/100, Reconstruction Error: 0.35360514922364206\n",
      "Epoch 74/100, Reconstruction Error: 0.35158844359719316\n",
      "Epoch 75/100, Reconstruction Error: 0.35050428395766353\n",
      "Epoch 76/100, Reconstruction Error: 0.3490997970765643\n",
      "Epoch 77/100, Reconstruction Error: 0.3478250210501501\n",
      "Epoch 78/100, Reconstruction Error: 0.3464808876311673\n",
      "Epoch 79/100, Reconstruction Error: 0.3453564650632734\n",
      "Epoch 80/100, Reconstruction Error: 0.34409387262414465\n",
      "Epoch 81/100, Reconstruction Error: 0.34293505792925033\n",
      "Epoch 82/100, Reconstruction Error: 0.3418692783617248\n",
      "Epoch 83/100, Reconstruction Error: 0.34026045740966065\n",
      "Epoch 84/100, Reconstruction Error: 0.33949099450880493\n",
      "Epoch 85/100, Reconstruction Error: 0.3381873461899814\n",
      "Epoch 86/100, Reconstruction Error: 0.336978670979591\n",
      "Epoch 87/100, Reconstruction Error: 0.33583930686841357\n",
      "Epoch 88/100, Reconstruction Error: 0.335461953546597\n",
      "Epoch 89/100, Reconstruction Error: 0.33467546554736055\n",
      "Epoch 90/100, Reconstruction Error: 0.33324592094638755\n",
      "Epoch 91/100, Reconstruction Error: 0.33215947363796156\n",
      "Epoch 92/100, Reconstruction Error: 0.33100693230602873\n",
      "Epoch 93/100, Reconstruction Error: 0.330276801999233\n",
      "Epoch 94/100, Reconstruction Error: 0.3293198617579571\n",
      "Epoch 95/100, Reconstruction Error: 0.32822369244004823\n",
      "Epoch 96/100, Reconstruction Error: 0.3276829883877351\n",
      "Epoch 97/100, Reconstruction Error: 0.3270414085354496\n",
      "Epoch 98/100, Reconstruction Error: 0.3262067099448952\n",
      "Epoch 99/100, Reconstruction Error: 0.3253047542682466\n",
      "Epoch 100/100, Reconstruction Error: 0.3242696963523433\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = np.random.randint(0, 2, size=(100, num_visible_units))\n",
    "\n",
    "\n",
    "rbm.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "[[0 0 1 0 1 1 1 0 0 0]\n",
      " [1 0 1 0 1 1 0 1 0 0]\n",
      " [1 1 0 0 0 0 1 1 0 0]\n",
      " [0 0 1 0 0 1 1 1 0 0]\n",
      " [0 1 0 0 1 1 0 0 0 1]\n",
      " [1 0 1 1 1 1 0 0 0 0]\n",
      " [1 1 0 1 0 1 0 0 0 1]\n",
      " [0 0 0 1 0 1 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 0 1 0 1]\n",
      " [1 0 1 0 1 1 1 1 1 1]\n",
      " [1 0 1 1 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0 0 1]\n",
      " [0 1 1 1 0 1 0 1 1 1]\n",
      " [1 1 1 0 1 0 1 0 1 1]\n",
      " [1 0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 1 0 0]\n",
      " [1 1 1 1 0 1 1 1 0 1]\n",
      " [0 1 0 1 0 0 0 1 1 0]\n",
      " [0 1 0 0 1 1 1 0 0 1]\n",
      " [1 0 1 1 0 0 1 0 1 0]\n",
      " [1 0 1 0 0 1 0 1 0 1]\n",
      " [1 1 0 1 0 1 1 0 0 0]\n",
      " [1 0 0 1 1 0 1 1 1 1]\n",
      " [1 0 1 1 1 0 0 0 1 1]\n",
      " [1 0 0 1 1 0 1 1 0 0]\n",
      " [1 0 1 1 0 1 0 0 0 0]\n",
      " [0 1 0 1 0 1 1 1 1 0]\n",
      " [1 1 1 0 1 0 0 1 1 1]\n",
      " [1 0 0 0 1 1 1 0 0 0]\n",
      " [1 1 0 0 1 1 1 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 1 1]\n",
      " [1 1 1 1 1 1 0 0 0 1]\n",
      " [1 1 0 1 0 0 0 1 0 1]\n",
      " [1 0 1 1 1 1 0 0 1 0]\n",
      " [0 1 1 0 0 1 0 0 0 0]\n",
      " [0 1 0 1 0 1 1 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 0 1 0 0 0 0 0]\n",
      " [1 0 0 1 0 1 0 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 0 1]\n",
      " [0 0 0 0 1 0 1 0 0 1]\n",
      " [0 0 1 1 1 1 0 1 0 1]\n",
      " [0 0 1 1 1 0 1 1 1 0]\n",
      " [1 0 0 0 1 1 1 1 0 0]\n",
      " [1 1 0 0 0 1 1 1 1 0]\n",
      " [1 1 1 0 1 1 1 1 1 0]\n",
      " [0 0 1 0 0 0 0 0 1 0]\n",
      " [1 1 1 1 0 1 0 1 1 1]\n",
      " [1 0 0 0 1 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1 1 1 1]\n",
      " [0 0 1 0 0 1 0 1 1 1]\n",
      " [1 0 0 0 1 1 0 0 1 0]\n",
      " [0 1 1 1 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 1 1 1 0 1 0]\n",
      " [1 1 0 1 0 0 1 1 1 1]\n",
      " [1 1 1 1 0 1 0 0 0 1]\n",
      " [0 1 0 1 1 1 1 1 0 0]\n",
      " [1 1 1 1 0 1 0 1 1 0]\n",
      " [0 1 0 0 1 0 1 1 1 1]\n",
      " [0 1 1 0 0 0 0 1 1 0]\n",
      " [1 1 0 0 0 1 1 0 0 0]\n",
      " [1 1 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 1 0 0 1 1 1 0]\n",
      " [0 0 1 0 0 0 0 0 1 0]\n",
      " [0 0 1 1 0 0 1 1 1 1]\n",
      " [0 0 1 0 1 0 0 0 0 1]\n",
      " [1 1 0 1 0 0 1 1 1 0]\n",
      " [1 1 1 0 1 1 1 1 0 1]\n",
      " [1 0 0 1 0 0 0 1 0 1]\n",
      " [0 0 1 1 1 0 0 1 1 0]\n",
      " [0 1 1 0 0 1 1 0 1 1]\n",
      " [0 0 0 0 1 0 0 0 1 1]\n",
      " [0 0 1 1 1 0 0 0 0 0]\n",
      " [1 0 0 0 1 1 1 0 1 0]\n",
      " [0 0 1 0 0 0 1 0 1 1]\n",
      " [0 0 0 0 1 0 1 1 1 1]\n",
      " [0 0 0 0 1 1 0 1 0 0]\n",
      " [1 0 1 1 1 1 0 1 1 0]\n",
      " [1 0 1 1 1 0 1 0 0 0]\n",
      " [0 1 0 0 1 1 1 0 1 1]\n",
      " [0 1 0 0 0 1 0 1 0 1]\n",
      " [0 0 1 0 0 0 1 1 0 0]\n",
      " [0 1 1 0 0 0 0 0 1 0]\n",
      " [0 1 0 1 1 0 1 1 1 0]\n",
      " [0 1 0 0 0 1 0 1 0 1]\n",
      " [1 1 1 0 0 0 1 0 1 1]\n",
      " [1 1 0 0 1 0 0 1 0 0]\n",
      " [1 0 1 1 0 1 1 1 0 1]\n",
      " [1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 1 1 1 1 0 1 0 1]\n",
      " [1 0 0 1 1 0 0 1 0 0]\n",
      " [0 1 1 1 1 1 0 0 1 1]\n",
      " [1 0 1 0 0 1 0 1 1 0]\n",
      " [1 0 0 1 0 0 1 0 0 1]\n",
      " [1 1 0 1 0 0 0 1 1 1]\n",
      " [0 1 1 1 0 1 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct input data\n",
    "reconstructed_data = rbm.reconstruct(data)\n",
    "print(\"Original Data:\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed Data:\n",
      "[[0.56130468 0.1924447  0.50180003 0.11829976 0.93109454 0.70236712\n",
      "  0.53427553 0.31239112 0.37535321 0.34866557]\n",
      " [0.70651578 0.20886168 0.75222074 0.35707602 0.82975438 0.8313513\n",
      "  0.1017416  0.42178057 0.26926217 0.37236515]\n",
      " [0.78440166 0.85617187 0.05163545 0.4762378  0.08006709 0.35135851\n",
      "  0.86876588 0.80362584 0.31508594 0.27923283]\n",
      " [0.45016059 0.44709795 0.601948   0.29597586 0.36303245 0.48574983\n",
      "  0.4570665  0.57452615 0.51369088 0.48158282]\n",
      " [0.54388357 0.41703033 0.40585497 0.08167409 0.80933826 0.89194087\n",
      "  0.21903928 0.31509888 0.46346521 0.34107108]\n",
      " [0.77086674 0.18464187 0.86040819 0.68676053 0.72569183 0.76153107\n",
      "  0.06202394 0.54584141 0.20955373 0.41004074]\n",
      " [0.88361809 0.73721561 0.34365289 0.58017549 0.09639002 0.84239489\n",
      "  0.08375054 0.76281178 0.17661597 0.28486423]\n",
      " [0.82660876 0.61286746 0.59201993 0.67563983 0.10885891 0.74181354\n",
      "  0.08340432 0.76410153 0.21506523 0.36803822]\n",
      " [0.87908174 0.55957635 0.2133808  0.40548705 0.37619565 0.69835328\n",
      "  0.42426454 0.67951614 0.15379434 0.24000545]\n",
      " [0.63109632 0.15815401 0.93930204 0.68385235 0.66392177 0.72026232\n",
      "  0.04277747 0.53257392 0.30738809 0.51397416]\n",
      " [0.40826493 0.20302798 0.67364252 0.18746154 0.86217779 0.55661205\n",
      "  0.51751421 0.36473328 0.50444566 0.45881274]\n",
      " [0.7632855  0.34498599 0.65282351 0.81564203 0.27364049 0.23965232\n",
      "  0.53026754 0.77942315 0.22152279 0.42838927]\n",
      " [0.49765522 0.54611626 0.41788706 0.222679   0.37169722 0.59427807\n",
      "  0.47735925 0.55155751 0.50313908 0.4233531 ]\n",
      " [0.34375183 0.28592455 0.91599166 0.23567567 0.504855   0.80658918\n",
      "  0.04878092 0.4253218  0.58237909 0.57309696]\n",
      " [0.25184667 0.77962399 0.81452004 0.67385329 0.01965734 0.46064257\n",
      "  0.11034269 0.76708801 0.76514722 0.68677453]\n",
      " [0.17095732 0.34692798 0.48818195 0.1734163  0.74629838 0.24080118\n",
      "  0.88681624 0.39467965 0.7739183  0.56349697]\n",
      " [0.71566592 0.29137115 0.82884764 0.60043548 0.41521076 0.67199405\n",
      "  0.09827868 0.63139267 0.26044239 0.44036412]\n",
      " [0.84571001 0.32517585 0.28942436 0.25978068 0.85258344 0.82507991\n",
      "  0.34261595 0.45255535 0.17210425 0.23236356]\n",
      " [0.74790592 0.6646239  0.52906328 0.74837818 0.05449557 0.40649574\n",
      "  0.3079601  0.82915923 0.28869539 0.42981762]\n",
      " [0.37423196 0.82633143 0.51722925 0.71168404 0.01895888 0.26463473\n",
      "  0.44584508 0.82373329 0.67269333 0.59679048]\n",
      " [0.36541239 0.47246884 0.15443076 0.08040967 0.82634865 0.49679733\n",
      "  0.89606342 0.35249595 0.62267367 0.37033405]\n",
      " [0.41009872 0.38006283 0.68753175 0.77913151 0.29156489 0.12053389\n",
      "  0.75263825 0.71901128 0.53928256 0.58006747]\n",
      " [0.72516069 0.45746216 0.85606158 0.62577239 0.14880806 0.79554397\n",
      "  0.02942628 0.69854327 0.28166519 0.46228878]\n",
      " [0.91426077 0.76895732 0.07252577 0.51680628 0.14864501 0.57352736\n",
      "  0.66489755 0.7949644  0.13726741 0.20469362]\n",
      " [0.53315528 0.40654669 0.31741052 0.64679495 0.58288025 0.15748595\n",
      "  0.90392541 0.64075008 0.45629142 0.43943269]\n",
      " [0.51019882 0.17519309 0.92098392 0.64968269 0.65234793 0.57459933\n",
      "  0.10778314 0.5286792  0.4098131  0.55206241]\n",
      " [0.91267494 0.29809901 0.18640179 0.63195245 0.81463041 0.4556861\n",
      "  0.76766648 0.63814259 0.10038067 0.21147877]\n",
      " [0.78759455 0.32200754 0.88055184 0.77897033 0.29031278 0.75045414\n",
      "  0.03329323 0.69307652 0.21209544 0.44544683]\n",
      " [0.52266699 0.87454219 0.10846987 0.4655917  0.04810484 0.28620708\n",
      "  0.83461327 0.78360177 0.57712932 0.41867969]\n",
      " [0.27577915 0.3374433  0.85225444 0.36500448 0.46220978 0.55119984\n",
      "  0.20584358 0.48775262 0.66437361 0.60464057]\n",
      " [0.79011032 0.22801079 0.18577472 0.11348635 0.95163571 0.70184759\n",
      "  0.76735912 0.35181788 0.19862253 0.21567873]\n",
      " [0.79618779 0.3479467  0.14694983 0.12004938 0.87785926 0.70377623\n",
      "  0.7493343  0.42364104 0.21090123 0.21699832]\n",
      " [0.79906814 0.41612171 0.77506553 0.73615379 0.17201817 0.60326902\n",
      "  0.10468922 0.7579291  0.20396363 0.41859579]\n",
      " [0.15174685 0.55186768 0.37559415 0.14828451 0.41755678 0.21675814\n",
      "  0.90350331 0.48658014 0.81566305 0.57622968]\n",
      " [0.75812492 0.21905784 0.87302181 0.69750614 0.6183313  0.77379704\n",
      "  0.04722311 0.57399407 0.22621638 0.42837641]\n",
      " [0.7692823  0.73539277 0.39185031 0.7163607  0.04536144 0.42481408\n",
      "  0.36822961 0.83619512 0.28479391 0.3971017 ]\n",
      " [0.6223795  0.15910295 0.91187255 0.51720535 0.76870611 0.78787415\n",
      "  0.05066695 0.45588521 0.31791699 0.47544326]\n",
      " [0.45840331 0.58745366 0.75658993 0.19936596 0.17099127 0.85372258\n",
      "  0.05250148 0.54864399 0.54227265 0.49601259]\n",
      " [0.40326696 0.85375507 0.11285955 0.25570142 0.09439987 0.37644401\n",
      "  0.83004265 0.68310759 0.67030455 0.43081147]\n",
      " [0.44498217 0.81253659 0.19581811 0.19898853 0.11549598 0.57763531\n",
      "  0.58804368 0.63801669 0.61912442 0.42234638]\n",
      " [0.71337412 0.23130354 0.63167748 0.30245893 0.8266211  0.77005476\n",
      "  0.21924099 0.43773092 0.26350018 0.34644407]\n",
      " [0.73046505 0.64833969 0.69828566 0.71223394 0.06542112 0.68993446\n",
      "  0.07035018 0.77690732 0.31513761 0.45101069]\n",
      " [0.44164766 0.32091981 0.72068955 0.63348057 0.49341189 0.29359931\n",
      "  0.53125471 0.60735965 0.50831179 0.53740654]\n",
      " [0.28141643 0.36925627 0.21069265 0.10808701 0.87300633 0.31125346\n",
      "  0.94441711 0.34726946 0.67522696 0.42680365]\n",
      " [0.63109632 0.15815401 0.93930204 0.68385235 0.66392177 0.72026232\n",
      "  0.04277747 0.53257392 0.30738809 0.51397416]\n",
      " [0.21307668 0.28359045 0.74244508 0.57885315 0.53887924 0.10984258\n",
      "  0.83703813 0.5749361  0.70968798 0.64046871]\n",
      " [0.85681147 0.27108192 0.16551055 0.21414918 0.91376362 0.65762336\n",
      "  0.7545026  0.45298869 0.14798262 0.20169686]\n",
      " [0.58657489 0.86338053 0.05915872 0.22153214 0.1071271  0.43320593\n",
      "  0.86425637 0.70429843 0.51590938 0.33091032]\n",
      " [0.56550714 0.40577969 0.26333889 0.13070962 0.79044527 0.65014165\n",
      "  0.6752278  0.40816376 0.42802941 0.33292443]\n",
      " [0.09357613 0.42227071 0.88604839 0.23341837 0.3483776  0.49320901\n",
      "  0.2376398  0.42629181 0.86956384 0.72016184]\n",
      " [0.57975547 0.69934855 0.82457864 0.76216586 0.02784231 0.63736788\n",
      "  0.04505781 0.80118575 0.46155255 0.56309611]\n",
      " [0.7267645  0.31633494 0.37347275 0.12704336 0.88121733 0.87981929\n",
      "  0.25594167 0.34589633 0.27979733 0.27479963]\n",
      " [0.30628326 0.72245234 0.60348883 0.7301469  0.03306735 0.13099662\n",
      "  0.67197038 0.81487249 0.69183213 0.6360908 ]\n",
      " [0.13101245 0.56518246 0.87504839 0.22472641 0.1510006  0.63387564\n",
      "  0.11499092 0.5024971  0.8405635  0.69577569]\n",
      " [0.6645414  0.26354468 0.421593   0.08737324 0.93249422 0.90315675\n",
      "  0.23226068 0.27119664 0.32671686 0.28714325]\n",
      " [0.42316665 0.72630066 0.50361849 0.78377942 0.03330266 0.11454793\n",
      "  0.7434044  0.84283514 0.59026201 0.58257519]\n",
      " [0.37460391 0.66124851 0.58883586 0.47066651 0.08882535 0.36227225\n",
      "  0.44768868 0.70944832 0.6244152  0.55680219]\n",
      " [0.31695822 0.39236942 0.1853795  0.08117073 0.8929938  0.46087269\n",
      "  0.91047274 0.30983499 0.65396935 0.39126254]\n",
      " [0.54377194 0.84757698 0.16614012 0.66811793 0.03198407 0.15856205\n",
      "  0.86192483 0.84225477 0.53540939 0.45955627]\n",
      " [0.77999026 0.55975714 0.83584479 0.75382921 0.06960596 0.77765405\n",
      "  0.02461684 0.77673669 0.2487835  0.45588345]\n",
      " [0.78795041 0.54553999 0.12020642 0.45362578 0.55980533 0.41460793\n",
      "  0.8407656  0.64243342 0.25457056 0.27114288]\n",
      " [0.71837471 0.66094943 0.80282961 0.75112792 0.03867711 0.72836784\n",
      "  0.03340224 0.79905123 0.32501008 0.48953653]\n",
      " [0.21903253 0.57444006 0.16453832 0.10535327 0.62889087 0.27188524\n",
      "  0.94902181 0.42815082 0.764196   0.46792283]\n",
      " [0.13248352 0.76155609 0.77442714 0.33815922 0.03768426 0.4582512\n",
      "  0.21663505 0.65481423 0.86068835 0.70615772]\n",
      " [0.84381625 0.7543865  0.07188822 0.22136523 0.2334427  0.66199754\n",
      "  0.69434596 0.68981235 0.21802651 0.2195331 ]\n",
      " [0.90392021 0.77293154 0.11431883 0.51939677 0.11066946 0.64148366\n",
      "  0.48443428 0.79701447 0.15012348 0.22788269]\n",
      " [0.50089578 0.84199803 0.17300526 0.61759414 0.03621093 0.1633902\n",
      "  0.86559997 0.82653519 0.56992356 0.47042663]\n",
      " [0.09357613 0.42227071 0.88604839 0.23341837 0.3483776  0.49320901\n",
      "  0.2376398  0.42629181 0.86956384 0.72016184]\n",
      " [0.26220352 0.46826479 0.71780538 0.73882477 0.18008451 0.10447096\n",
      "  0.7566     0.71945786 0.69231117 0.65088524]\n",
      " [0.28682696 0.14814089 0.92302531 0.23652268 0.82218113 0.68129078\n",
      "  0.1344704  0.33653491 0.59976924 0.58432824]\n",
      " [0.63375702 0.87356297 0.08102151 0.59721062 0.04278068 0.20355576\n",
      "  0.89642774 0.8308571  0.47381812 0.38153425]\n",
      " [0.75855726 0.31915399 0.31883989 0.24044613 0.80785862 0.66968506\n",
      "  0.55860823 0.47713775 0.23967974 0.28272385]\n",
      " [0.82272056 0.53124509 0.59278153 0.77232833 0.10517326 0.43819467\n",
      "  0.26915218 0.81656362 0.1948437  0.38964368]\n",
      " [0.31247044 0.2426967  0.90293468 0.64203923 0.53409415 0.3974682\n",
      "  0.22782594 0.53883375 0.61133974 0.63169707]\n",
      " [0.0906981  0.70780163 0.69792528 0.15184556 0.11085083 0.48214353\n",
      "  0.37384983 0.51463682 0.89570075 0.69199487]\n",
      " [0.1267336  0.32197436 0.71318706 0.15728133 0.75191146 0.43701991\n",
      "  0.60254826 0.32753615 0.82581736 0.62252732]\n",
      " [0.60913094 0.1502085  0.90973814 0.63720016 0.71432606 0.59576454\n",
      "  0.11555269 0.53114353 0.31615256 0.50168218]\n",
      " [0.65667214 0.26472487 0.18990628 0.0850975  0.94452068 0.66506885\n",
      "  0.81005137 0.31850978 0.32028179 0.26045206]\n",
      " [0.08592465 0.35382408 0.77698939 0.23156493 0.49799788 0.18785416\n",
      "  0.77380974 0.444978   0.866233   0.70242165]\n",
      " [0.17261031 0.38538886 0.32127076 0.13575494 0.79080208 0.21465077\n",
      "  0.94480893 0.37645726 0.78090349 0.5266898 ]\n",
      " [0.69870729 0.27935885 0.41393154 0.11931344 0.9032063  0.87175109\n",
      "  0.2678289  0.32474382 0.29574347 0.2868746 ]\n",
      " [0.72102981 0.17583687 0.91392282 0.72689256 0.64928896 0.7305357\n",
      "  0.04670347 0.5674247  0.24338805 0.46581597]\n",
      " [0.83792127 0.17657457 0.5938513  0.71733467 0.77150322 0.36296531\n",
      "  0.57157676 0.64232159 0.1421186  0.33083399]\n",
      " [0.2117845  0.55576347 0.17319267 0.07671862 0.75108688 0.43932794\n",
      "  0.9043978  0.34200456 0.77866535 0.4532387 ]\n",
      " [0.50491221 0.80460853 0.36320081 0.25132444 0.08592765 0.77180945\n",
      "  0.18905856 0.64260776 0.57116918 0.43734216]\n",
      " [0.28434826 0.46385258 0.6145558  0.48866817 0.26044502 0.16170576\n",
      "  0.78741373 0.6525252  0.66430724 0.58954791]\n",
      " [0.09183984 0.70606871 0.80389319 0.21000468 0.07449157 0.51748708\n",
      "  0.21592921 0.55123695 0.89392545 0.7212817 ]\n",
      " [0.43411064 0.58899432 0.16501572 0.42875249 0.46294665 0.18447449\n",
      "  0.93916138 0.61519558 0.58263208 0.42991773]\n",
      " [0.50491221 0.80460853 0.36320081 0.25132444 0.08592765 0.77180945\n",
      "  0.18905856 0.64260776 0.57116918 0.43734216]\n",
      " [0.17770469 0.68359403 0.49955748 0.2807083  0.10995281 0.21810218\n",
      "  0.76998757 0.64404657 0.80204406 0.6202865 ]\n",
      " [0.90913475 0.52990281 0.13503303 0.40163717 0.5261795  0.68099338\n",
      "  0.57362134 0.66212549 0.12086224 0.19885944]\n",
      " [0.79806986 0.35790885 0.72490631 0.79935111 0.24037838 0.40484851\n",
      "  0.2639216  0.77032504 0.19612637 0.41685853]\n",
      " [0.66933789 0.8469026  0.10989171 0.63448651 0.04520883 0.21312946\n",
      "  0.86261484 0.83605692 0.42435815 0.38156115]\n",
      " [0.79078806 0.27467275 0.87058729 0.77265804 0.42193438 0.74456404\n",
      "  0.042248   0.65762861 0.20514681 0.43139648]\n",
      " [0.9140272  0.25236242 0.35286349 0.69134702 0.7715429  0.5198648\n",
      "  0.54566146 0.65361128 0.09280047 0.23899538]\n",
      " [0.1445048  0.27459269 0.92277871 0.30168734 0.59116547 0.59358787\n",
      "  0.14144559 0.38024597 0.79689478 0.68710107]\n",
      " [0.61145129 0.48475017 0.83741236 0.41966978 0.17470121 0.82367802\n",
      "  0.03568567 0.62685949 0.38590986 0.48221526]\n",
      " [0.70609665 0.53501266 0.27052075 0.69642091 0.30529904 0.22115862\n",
      "  0.82198598 0.74352239 0.31925413 0.38059561]\n",
      " [0.45276612 0.81583346 0.50316422 0.74298344 0.01960443 0.2712688\n",
      "  0.43395234 0.8366377  0.6022496  0.56725709]\n",
      " [0.34098756 0.76085975 0.80838527 0.69429561 0.02215089 0.51651881\n",
      "  0.08854842 0.7762959  0.68567702 0.64778753]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Reconstructed Data:\")\n",
    "print(reconstructed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
