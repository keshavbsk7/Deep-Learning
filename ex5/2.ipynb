{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense,Layer,Dropout\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    Flatten(input_shape=(28,28,3), name='layers_flatten'),\n",
    "    Dense(512, activation='relu', name='layers_dense'),\n",
    "    Dense(10, activation='softmax', name='layers_dense_2')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "img_height = 28\n",
    "img_width = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 407 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"wheat_leaf\"\n",
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "dataset = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode= 'int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    "    interpolation='bilinear',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "num_classes = dataset.reduce(0, lambda x, _: x + 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 22s 982ms/step - loss: 412.6892 - accuracy: 0.3612\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 22s 1s/step - loss: 114.2732 - accuracy: 0.5455\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 21s 1s/step - loss: 80.7258 - accuracy: 0.5037\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 21s 1s/step - loss: 69.2688 - accuracy: 0.6388\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 21s 1s/step - loss: 22.0339 - accuracy: 0.7273\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 19s 889ms/step - loss: 8.5501 - accuracy: 0.8280\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 12s 596ms/step - loss: 7.3179 - accuracy: 0.8501\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 12s 604ms/step - loss: 18.1018 - accuracy: 0.7420\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 13s 701ms/step - loss: 10.3437 - accuracy: 0.8182\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 12s 590ms/step - loss: 56.7027 - accuracy: 0.6290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bd8f6a0e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir=\"./log\", histogram_freq=1)\n",
    "def log_images(epoch, logs):\n",
    "    dataset_iter = iter(dataset)\n",
    "    images, _ = next(dataset_iter)\n",
    "    with tf.summary.create_file_writer(\"./log\").as_default():\n",
    "        tf.summary.image(\"Training data\", images, step=epoch)\n",
    "\n",
    "\n",
    "image_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_images)\n",
    "\n",
    "model.fit(dataset, epochs=10, batch_size=32, callbacks=[tensorboard_callback,image_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 26908), started 2 days, 23:13:25 ago. (Use '!kill 26908' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-78ada67c07c70095\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-78ada67c07c70095\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir =log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
